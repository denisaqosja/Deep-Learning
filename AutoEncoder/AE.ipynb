{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 256\n",
    "transforms_ = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()])\n",
    "\n",
    "def train_data():\n",
    "    train_dataset = datasets.FashionMNIST(root=\"../data/\", train=True, download=True, transform=transforms_)\n",
    "\n",
    "    return train_dataset\n",
    "\n",
    "def test_data():\n",
    "    test_dataset = datasets.FashionMNIST(root=\"../data/\", train=False, download=True, transform=transforms.ToTensor() )\n",
    "    \n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VariationalAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=16, bias=True)\n",
       "    (1): Linear(in_features=16, out_features=2048, bias=True)\n",
       "  )\n",
       "  (fc1_enc): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (fc2_mean): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (fc2_var): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (fc_dec1): Linear(in_features=16, out_features=128, bias=True)\n",
       "  (fc_dec2): Linear(in_features=128, out_features=2048, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): ConvTranspose2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(128, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VariationalAE(nn.Module):\n",
    "    def __init__(self, size=[128, 64, 32], latent_dim=16):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 1x28x28\n",
    "            nn.Conv2d(in_channels=1, out_channels=size[0], kernel_size=5, stride=1),\n",
    "            nn.ReLU(),\n",
    "            # 128x24x24\n",
    "            nn.Conv2d(in_channels=size[0], out_channels=size[1], kernel_size=5, stride=1),\n",
    "            # 64x20x20\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=size[1], out_channels=size[2], kernel_size=5, stride=1),\n",
    "            # 32x20x20\n",
    "        )\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        # 32x8x8\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            # encoder\n",
    "            nn.Linear(in_features=size[2]*8*8, out_features=latent_dim),\n",
    "            # dec\n",
    "            nn.Linear(in_features=latent_dim, out_features=size[2]*8*8)\n",
    "        )\n",
    "\n",
    "        self.fc1_enc = nn.Linear(in_features=size[2]*8*8, out_features=128)\n",
    "        self.fc2_mean = nn.Linear(in_features=128, out_features=latent_dim)\n",
    "        self.fc2_var = nn.Linear(in_features=128, out_features=latent_dim)\n",
    "\n",
    "        self.fc_dec1 = nn.Linear(in_features=latent_dim, out_features=128)\n",
    "        self.fc_dec2 = nn.Linear(in_features=128, out_features=size[2]*8*8)\n",
    "\n",
    "        self.out_layer = nn.MaxUnpool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=size[2], out_channels=size[1], kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=size[1], out_channels=size[0], kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=size[0], out_channels=1, kernel_size=5),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def reparametrize(self, mean, var):\n",
    "        eps = torch.randn(var.shape)\n",
    "        z = eps * var + mean\n",
    "        return z\n",
    "\n",
    "    def forward(self, input):\n",
    "        out_enc = self.encoder(input)\n",
    "        out_pool, out_indices = self.pool(out_enc)\n",
    "        \n",
    "        #flattening\n",
    "        batch_size = out_enc.shape[0]\n",
    "        out_flattened = out_pool.view(batch_size, -1)\n",
    "    \n",
    "        out_fc1 = self.fc1_enc(out_flattened)\n",
    "        mean = self.fc2_mean(out_fc1)\n",
    "        var = self.fc2_var(out_fc1)\n",
    "        z = self.reparametrize(mean, var)\n",
    "    \n",
    "        out_fc_dec1 = self.fc_dec1(z)\n",
    "        out_fc_dec2 = self.fc_dec2(out_fc_dec1)\n",
    "     \n",
    "        # unflattening\n",
    "        out_unflattened = out_fc_dec2.view(out_pool.shape)\n",
    "     \n",
    "        out_unpool = nn.MaxUnpool2d(kernel_size=2, stride=2)(out_unflattened, out_indices)\n",
    "        \n",
    "        recons = self.decoder(out_unpool)\n",
    "        \n",
    "        return recons\n",
    "    \n",
    "model = VariationalAE()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-4\n",
    "EPOCHS = 10\n",
    "optimizerName = \"Adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train_dataset = train_data()\n",
    "test_dataset = test_data()\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "#setup model \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate)\n",
    "lossFunction = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)      \n",
    "\n",
    "#save images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------EPOCH 0--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  2%|▎         | 1/40 [00:05<03:45,  5.79s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|▌         | 2/40 [00:09<03:15,  5.15s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 3/40 [00:14<03:06,  5.04s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|█         | 4/40 [00:17<02:46,  4.63s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|█▎        | 5/40 [00:24<02:59,  5.12s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█▌        | 6/40 [00:29<02:57,  5.23s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|█▊        | 7/40 [00:36<03:05,  5.61s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|██        | 8/40 [00:42<03:07,  5.85s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|██▎       | 9/40 [00:48<03:00,  5.82s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 10/40 [00:54<03:01,  6.07s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██▊       | 11/40 [00:59<02:43,  5.62s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███       | 12/40 [01:05<02:42,  5.80s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|███▎      | 13/40 [01:12<02:44,  6.09s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|███▌      | 14/40 [01:18<02:36,  6.00s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/40 [01:24<02:34,  6.16s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 16/40 [01:29<02:17,  5.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████▎     | 17/40 [01:35<02:10,  5.68s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|████▌     | 18/40 [01:39<01:56,  5.29s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|████▊     | 19/40 [01:43<01:41,  4.82s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 20/40 [01:47<01:34,  4.74s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|█████▎    | 21/40 [01:52<01:27,  4.63s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████▌    | 22/40 [01:56<01:21,  4.53s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████▊    | 23/40 [02:01<01:18,  4.63s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████    | 24/40 [02:07<01:19,  4.94s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|██████▎   | 25/40 [02:11<01:12,  4.83s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|██████▌   | 26/40 [02:16<01:06,  4.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|██████▊   | 27/40 [02:22<01:08,  5.24s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|███████   | 28/40 [02:28<01:05,  5.44s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████▎  | 29/40 [02:33<00:59,  5.43s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 30/40 [02:41<01:00,  6.03s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|███████▊  | 31/40 [02:45<00:49,  5.55s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|████████  | 32/40 [02:50<00:42,  5.35s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|████████▎ | 33/40 [02:55<00:36,  5.15s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████▌ | 34/40 [03:00<00:30,  5.10s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|████████▊ | 35/40 [03:07<00:28,  5.71s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|█████████ | 36/40 [03:11<00:21,  5.28s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 92%|█████████▎| 37/40 [03:17<00:16,  5.34s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|█████████▌| 38/40 [03:22<00:10,  5.26s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████▊| 39/40 [03:26<00:05,  5.06s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 40/40 [03:27<00:00,  5.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing loss: 0.16791316010057927\n",
      "--------------EPOCH 1--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  2%|▎         | 1/40 [00:08<05:28,  8.41s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|▌         | 2/40 [00:15<05:00,  7.92s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 3/40 [00:21<04:30,  7.31s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|█         | 4/40 [00:24<03:44,  6.24s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|█▎        | 5/40 [00:27<03:04,  5.26s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█▌        | 6/40 [00:30<02:35,  4.57s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|█▊        | 7/40 [00:33<02:15,  4.10s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|██        | 8/40 [00:36<01:59,  3.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|██▎       | 9/40 [00:39<01:50,  3.57s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 10/40 [00:43<01:49,  3.65s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██▊       | 11/40 [00:47<01:49,  3.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███       | 12/40 [00:51<01:42,  3.65s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|███▎      | 13/40 [00:54<01:33,  3.45s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|███▌      | 14/40 [00:56<01:25,  3.29s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/40 [00:59<01:20,  3.21s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 16/40 [01:03<01:18,  3.29s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████▎     | 17/40 [01:08<01:29,  3.90s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|████▌     | 18/40 [01:12<01:23,  3.78s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|████▊     | 19/40 [01:15<01:14,  3.52s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 20/40 [01:18<01:07,  3.35s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|█████▎    | 21/40 [01:21<01:04,  3.38s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████▌    | 22/40 [01:25<01:03,  3.55s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████▊    | 23/40 [01:29<01:03,  3.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████    | 24/40 [01:34<01:06,  4.13s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|██████▎   | 25/40 [01:39<01:05,  4.36s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|██████▌   | 26/40 [01:44<01:03,  4.53s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|██████▊   | 27/40 [01:48<00:57,  4.42s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|███████   | 28/40 [01:52<00:49,  4.13s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████▎  | 29/40 [01:55<00:43,  3.94s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 30/40 [01:59<00:39,  3.95s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|███████▊  | 31/40 [02:04<00:36,  4.07s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|████████  | 32/40 [02:09<00:35,  4.49s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|████████▎ | 33/40 [02:13<00:31,  4.47s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████▌ | 34/40 [02:18<00:27,  4.52s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|████████▊ | 35/40 [02:23<00:22,  4.50s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|█████████ | 36/40 [02:27<00:17,  4.49s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 92%|█████████▎| 37/40 [02:33<00:15,  5.06s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|█████████▌| 38/40 [02:39<00:10,  5.29s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████▊| 39/40 [02:46<00:05,  5.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 40/40 [02:47<00:00,  4.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing loss: 0.16791329458355903\n",
      "--------------EPOCH 2--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  2%|▎         | 1/40 [00:06<04:25,  6.80s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|▌         | 2/40 [00:12<04:10,  6.60s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 3/40 [00:19<04:01,  6.51s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|█         | 4/40 [00:24<03:45,  6.26s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-1808f7a44b98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#train_loss = train_epoch()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m#print(f\"Training loss: {train_loss}, training time: {time.time() - start_training_time}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Testing loss: {test_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-1808f7a44b98>\u001b[0m in \u001b[0;36mtest_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mrecons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtest_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-b844cdd153cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mout_unpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxUnpool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_unflattened\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mrecons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_unpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrecons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    923\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    924\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_epoch():\n",
    "    train_losses = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batchId, (images, labels) in enumerate(tqdm(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        recons = model(images)\n",
    "        loss = lossFunction(recons, images)\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_epoch():\n",
    "    test_losses = []\n",
    "\n",
    "    for batchId, (images, _) in enumerate(tqdm(test_loader)):\n",
    "        images = images.to(device)\n",
    "\n",
    "        recons = model(images)\n",
    "        loss = lossFunction(recons, images)\n",
    "        test_losses.append(loss.item())\n",
    "\n",
    "    test_loss = np.mean(test_losses)\n",
    "\n",
    "    return test_loss\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_training_time = time.time()\n",
    "    print(f\"--------------EPOCH {epoch}--------------\")\n",
    "    #train_loss = train_epoch()\n",
    "    #print(f\"Training loss: {train_loss}, training time: {time.time() - start_training_time}\")\n",
    "    test_loss = test_epoch()\n",
    "    print(f\"Testing loss: {test_loss}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16791329458355903"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-ca104abc950d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"green\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Test loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"best\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \"\"\"\n\u001b[1;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (1,)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "epochs = np.arange(EPOCHS)\n",
    "ax[0].plot(epochs, train_loss, c=\"green\", label=\"Train loss\")\n",
    "ax[0].plot(epochs, valid_loss, c=\"blue\", label=\"Test loss\")\n",
    "ax[0].legend(loc=\"best\")\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"MSE Loss\")\n",
    "ax[0].set_title(\"Loss curves\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
